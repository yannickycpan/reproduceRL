{"targetUpdateFrequency": 1000, "sweeps": {"epsilon": [0.1], "epsilonDecay": [1.0], "epsilonMin": [0.01], "alpha": [0.001, 0.0001], "queueSize": [1000000], "gaAlpha": [0.1], "nFromQueue": [16], "planningSteps": [30], "noiseScale": [0.05], "gamma": [0.99], "useTrueModel": [true], "n_h1": [32], "n_h2": [32]}, "warmUpSteps": 5000, "bufferSize": 1000000, "batchSize": 32, "evalEverySteps": 500, "numEvalEpisodes": 1, "maxTotalSamples": 50000, "type": null, "useAtari": false, "envName": "GridWorld", "name": "ModelDQN-LogTDHC", "saveName": "ModelDQN-LogTDHC", "sparseReward": false, "alpha": 0.001, "epsilon": 0.1, "epsilonDecay": 1.0, "epsilonMin": 0.01, "gaAlpha": 0.1, "gamma": 0.99, "nFromQueue": 16, "n_h1": 32, "n_h2": 32, "noiseScale": 0.05, "planningSteps": 30, "queueSize": 1000000, "useTrueModel": true, "seed": 0, "stateBounded": false, "stateDim": 2, "actionDim": 4, "actionBound": null, "statescale": 1.0, "qnntype": "Regular", "trainFrequency": 1, "auxiUpdateFrequency": 1000, "record_every": 100000, "model_n_h1": 64, "model_n_h2": 64, "numGradientSteps": 100, "queue_batchSize": 16, "gamma_thres": -1, "kaap": 1.0, "varianceFactor": 0.1, "auxibatchSize": 64, "numAuxUpdate": 1, "saveModel": true, "useSavedModel": false, "notTrain": false, "tau": 0.001, "critic_factor": 10.0, "stateBound": null, "percentileThres": 75, "scaleState4Linear": true, "lam": 0.95, "resetFrequency": 10000, "forgetRate": -1, "radius": 10.0, "useStretch": 0, "liftProjectState": 0, "maxgaloops": 200, "numSCsamples": 20, "search_control_frequency": 1, "startTravel": 0, "stopTravel": 1000000, "meta_learning_rate": 0.001, "policy_alpha": 1e-05, "model_learning_rate": 0.0001, "innerAlpha": 0.1, "critic_times": 1, "planDepth": 5, "useRollout": 0, "useTargetHC": 1, "mixwithValue": 0, "priorityScale": 1.0, "useGAE": 1, "ppoClipRatio": 0.1, "klDelta": 0.01, "entropy_reg": 0.0, "PSDreg": 1.0, "Anormreg": 1.0, "decor_reg": 0.0, "model_loss_weight": 1.0, "phi_norm": 0.0, "model_reg_weight": 0.0, "F_learning_rate": 0.0, "trainR": false, "cotrain_phisp": false, "action_model": false, "reward_loss_weight": 0.0, "useTarNN_phisp": true, "reward_scale": 1.0, "usetanh": 0, "allsparseact": false, "n_tiles": 20, "extra_strength": false, "n_tilings": 1, "sparse_dim": null, "test_tiling": false, "actfunctypeFTA": "linear", "actfunctypeFTAstrength": "linear", "fta_input_max": 1.0, "outofbound_reg": 0.0, "self_strength": false, "sparseactor": 0, "spexpscalor": 0.05, "spexpscaloradd": 0.05, "continoisescale": 1.0, "use_extreme_init": true, "temperature": 1.0}